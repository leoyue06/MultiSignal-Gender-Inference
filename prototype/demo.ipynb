{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a9d57e9",
   "metadata": {},
   "source": [
    "# Multi-Signal Gender Inference Demo\n",
    "\n",
    "This notebook demonstrates how the system combines **three independent signals**  \n",
    "(name, sport gender, and photo) to infer a likely gender with weighted evidence.\n",
    "\n",
    "The notebook walks through:\n",
    "\n",
    "1. Loading the inference engine  \n",
    "2. Creating several example athlete profiles  \n",
    "3. Running inference on each  \n",
    "4. Inspecting how each signal contributed to the final result  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f3a9e",
   "metadata": {},
   "source": [
    "## Imports & Auto-Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d2c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from inference import infer_gender, InferenceConfig\n",
    "from dataclasses import asdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00cb84c",
   "metadata": {},
   "source": [
    "## Quick Test: Calling the Vision Model Directly\n",
    "\n",
    "Before running the full inference pipeline, it is useful to test the photo-based\n",
    "signal alone. The following code calls:\n",
    "\n",
    "```python\n",
    "from signals import get_photo_signal\n",
    "\n",
    "signal = get_photo_signal(\"../examples/test_1.jpg\")\n",
    "signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d2d1128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Signal(source='photo', p_male=0.0, p_female=1.0, quality='high', raw_value='../examples/test_1.jpg', meta={'notes': 'The image features a single female face with clear visibility and good lighting.'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from signals import get_photo_signal\n",
    "\n",
    "signal = get_photo_signal(\"../examples/test_1.jpg\")\n",
    "signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6699e31c",
   "metadata": {},
   "source": [
    "⚠️ **Note on the vision model and processing time**\n",
    "\n",
    "When you run this block, the image is sent to OpenAI’s vision model for\n",
    "processing, which may take a few seconds depending on network latency and\n",
    "model load. The model returns a structured JSON response containing\n",
    "`p_male`, `p_female`, and a `quality` label.\n",
    "\n",
    "---\n",
    "\n",
    "⚠️ **Limitations of the vision-based confidence**\n",
    "\n",
    "In this prototype, the photo signal comes from an LLM-based vision model\n",
    "(**GPT-4o-mini**) rather than a dedicated **CNN/ResNet classifier** with a\n",
    "trained softmax head. The numeric values `p_male` and `p_female` are therefore\n",
    "**confidence-like scores generated through prompting**, not calibrated probabilities produced\n",
    "by a supervised computer-vision model.\n",
    "\n",
    "Because we did not build or fine-tune a standalone classifier due to time\n",
    "constraints, the fusion logic intentionally:\n",
    "\n",
    "- assigns **lower base weight** to the photo signal  \n",
    "- **down-weights** it further for low-quality cases (group photos, blurry images, multiple faces)\n",
    "\n",
    "This helps reduce the influence of any potential misclassification from the\n",
    "vision model and keeps the overall inference stable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b81bf3",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td align=\"center\">\n",
    "      <img src=\"../examples/test_1.jpg\" width=\"160\"><br>\n",
    "      <sub>test_1</sub>\n",
    "    </td>\n",
    "    <td align=\"center\">\n",
    "      <img src=\"../examples/test_2.jpg\" width=\"160\"><br>\n",
    "      <sub>test_2</sub>\n",
    "    </td>\n",
    "    <td align=\"center\">\n",
    "      <img src=\"../examples/test_3.jpg\" width=\"160\"><br>\n",
    "      <sub>test_3 (group photo)</sub>\n",
    "    </td>\n",
    "    <td align=\"center\">\n",
    "      <img src=\"../examples/test_4.jpg\" width=\"160\"><br>\n",
    "      <sub>test_4</sub>\n",
    "    </td>\n",
    "    <td align=\"center\">\n",
    "      <img src=\"../examples/test_5.jpg\" width=\"160\"><br>\n",
    "      <sub>test_5</sub>\n",
    "    </td>\n",
    "    <td align=\"center\">\n",
    "      <img src=\"../examples/test_6.jpg\" width=\"160\"><br>\n",
    "      <sub>test_6</sub>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089ab4d1",
   "metadata": {},
   "source": [
    "## 1. Create Example Athlete Profiles\n",
    "\n",
    "These profiles simulate real cases the system might encounter.\n",
    "\n",
    "Each profile includes:\n",
    "- **first name**  \n",
    "- **sport gender**  \n",
    "- **photo path**  \n",
    "- optional flags like `low_quality_photo`, `group_photo`, or explicit `gender`\n",
    "\n",
    "Explicit gender (e.g., “Female”) **skips the entire inference pipeline**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeda7040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo input profiles for the multi-signal gender inference pipeline.\n",
    "# Each profile intentionally varies signal quality, sport labels, and image context.\n",
    "\n",
    "profiles = [\n",
    "    # 1. Female-leaning name, no sport gender, high-quality image\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"first_name\": \"Mary\",\n",
    "        \"sport_gender\": None,\n",
    "        \"photo_path\": \"../examples/test_1.jpg\",\n",
    "    },\n",
    "\n",
    "    # 2. Neutral sport label, image-only + name signal\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"first_name\": \"Alice\",\n",
    "        \"sport_gender\": \"Unknown\",\n",
    "        \"photo_path\": \"../examples/test_2.jpg\",\n",
    "    },\n",
    "\n",
    "    # 3. Group/low-context image → photo signal heavily down-weighted\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"first_name\": \"Alex\",\n",
    "        \"sport_gender\": \"Unknown\",\n",
    "        \"photo_path\": \"../examples/test_3.jpg\",\n",
    "        \"group_photo\": True,\n",
    "    },\n",
    "\n",
    "    # 4. Clear male signals from both name + sport + image\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"first_name\": \"James\",\n",
    "        \"sport_gender\": \"Male\",\n",
    "        \"photo_path\": \"../examples/test_4.jpg\",\n",
    "    },\n",
    "\n",
    "    # 5. Female image but sport listed as male → conflict test case\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"first_name\": \"Emily\",\n",
    "        \"sport_gender\": \"Male\",\n",
    "        \"photo_path\": \"../examples/test_5.jpg\",\n",
    "    },\n",
    "\n",
    "    # 6. Strong male signals across name, sport, and image\n",
    "    {\n",
    "        \"id\": 6,\n",
    "        \"first_name\": \"Michael\",\n",
    "        \"sport_gender\": \"Male\",\n",
    "        \"photo_path\": \"../examples/test_6.jpg\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d782058",
   "metadata": {},
   "source": [
    "## 2. Run the Inference Engine\n",
    "\n",
    "The following cell runs inference on every profile and displays:\n",
    "\n",
    "- inferred gender  \n",
    "- confidence score  \n",
    "- probability of male / female  \n",
    "- whether explicit gender caused inference to be skipped  \n",
    "\n",
    "This gives a high-level view of system behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f00c903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>sport_gender</th>\n",
       "      <th>explicit_gender</th>\n",
       "      <th>inferred_gender</th>\n",
       "      <th>confidence</th>\n",
       "      <th>p_male</th>\n",
       "      <th>p_female</th>\n",
       "      <th>skipped_due_to_explicit_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mary</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.907</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Alice</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>None</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.908</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>None</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.508</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>James</td>\n",
       "      <td>Male</td>\n",
       "      <td>None</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.003</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Male</td>\n",
       "      <td>None</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.303</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Male</td>\n",
       "      <td>None</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.003</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id first_name sport_gender explicit_gender inferred_gender  confidence  \\\n",
       "0   1       Mary         None            None          Female       0.907   \n",
       "1   2      Alice      Unknown            None          Female       0.908   \n",
       "2   3       Alex      Unknown            None         Unknown       0.508   \n",
       "3   4      James         Male            None            Male       0.997   \n",
       "4   5      Emily         Male            None            Male       0.697   \n",
       "5   6    Michael         Male            None            Male       0.997   \n",
       "\n",
       "   p_male  p_female  skipped_due_to_explicit_gender  \n",
       "0   0.093     0.907                           False  \n",
       "1   0.092     0.908                           False  \n",
       "2   0.492     0.508                           False  \n",
       "3   0.997     0.003                           False  \n",
       "4   0.697     0.303                           False  \n",
       "5   0.997     0.003                           False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "config = InferenceConfig(min_confidence=0.6)\n",
    "rows = []\n",
    "\n",
    "for p in profiles:\n",
    "    result = infer_gender(p, config=config)\n",
    "    row = {\n",
    "        \"id\": p[\"id\"],\n",
    "        \"first_name\": p.get(\"first_name\"),\n",
    "        \"sport_gender\": p.get(\"sport_gender\"),\n",
    "        \"explicit_gender\": p.get(\"gender\"),\n",
    "        \"inferred_gender\": result.inferred_gender,\n",
    "        \"confidence\": round(result.confidence, 3),\n",
    "        \"p_male\": round(result.p_male, 3),\n",
    "        \"p_female\": round(result.p_female, 3),\n",
    "        \"skipped_due_to_explicit_gender\": result.skipped_due_to_explicit_gender,\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94fef26",
   "metadata": {},
   "source": [
    "### Note on Current Photo Classification Limitations\n",
    "\n",
    "Right now, the system is not using a trained face-gender classifier with numerical confidence.  \n",
    "Instead, it relies on an LLM vision model (OpenAI 4o-mini).\n",
    "\n",
    "Because LLM-based photo outputs are less quantitatively reliable, the weighting logic intentionally prioritizes  \n",
    "**name-based priors** and **sport-gender signals** over photo signals.  \n",
    "This can lead to cases where the image appears clearly female or male, but the final inference leans the other way  \n",
    "due to the stronger, more stable non-photo signals.\n",
    "\n",
    "That said, the photo signal is **not ignored**.  \n",
    "If you compare the confidence and p_male / p_female values for the examples using `test_4`, `test_5`, and `test_6`,  \n",
    "you can see that the photo input still nudges the final probabilities – the scores shift in response to the image,  \n",
    "even though name and sport remain the primary drivers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed19491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Signal(source='photo', p_male=0.0, p_female=1.0, quality='high', raw_value='../examples/test_5.jpg', meta={'notes': 'The image features a single female athlete in action, indicating high quality.'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from signals import get_photo_signal\n",
    "\n",
    "signal = get_photo_signal(\"../examples/test_5.jpg\")\n",
    "signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543233a4",
   "metadata": {},
   "source": [
    "## 3. Inspect Attribution for One Profile\n",
    "\n",
    "The table above gives the final result, but sometimes we want to see:\n",
    "\n",
    "- how each signal was weighted  \n",
    "- how much each contributed  \n",
    "- how low/medium/high quality affected the model  \n",
    "- whether context flags (group photo, low quality) reduced photo weight  \n",
    "\n",
    "Below, we inspect the full attribution for **Profile 3 (Alex)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92d1969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile: {'id': 3, 'first_name': 'Alex', 'sport_gender': 'Unknown', 'photo_path': '../examples/test_3.jpg', 'group_photo': True}\n",
      "Inference result: Unknown confidence 0.508\n",
      "\n",
      "Attribution:\n",
      "[ { 'meta': {'ambiguous': True, 'db_hit': True},\n",
      "    'p_female': 0.45,\n",
      "    'p_male': 0.55,\n",
      "    'quality': 'medium',\n",
      "    'source': 'name',\n",
      "    'weight': 0.4186046511627907,\n",
      "    'weighted_p_female': 0.18837209302325583,\n",
      "    'weighted_p_male': 0.23023255813953492},\n",
      "  { 'meta': {'reason': 'neutral_sport_category'},\n",
      "    'p_female': 0.5,\n",
      "    'p_male': 0.5,\n",
      "    'quality': 'medium',\n",
      "    'source': 'sport',\n",
      "    'weight': 0.5232558139534884,\n",
      "    'weighted_p_female': 0.2616279069767442,\n",
      "    'weighted_p_male': 0.2616279069767442},\n",
      "  { 'meta': { 'notes': 'The image features multiple female athletes running on '\n",
      "                       'a track.'},\n",
      "    'p_female': 1.0,\n",
      "    'p_male': 0.0,\n",
      "    'quality': 'high',\n",
      "    'source': 'photo',\n",
      "    'weight': 0.05813953488372094,\n",
      "    'weighted_p_female': 0.05813953488372094,\n",
      "    'weighted_p_male': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "profile = profiles[2]  # Alex\n",
    "result = infer_gender(profile, config=config)\n",
    "print(\"Profile:\", profile)\n",
    "print(\"Inference result:\", result.inferred_gender, \"confidence\", round(result.confidence, 3))\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "print(\"\\nAttribution:\")\n",
    "pp.pprint(result.attribution)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "echo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
